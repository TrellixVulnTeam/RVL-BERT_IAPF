---
RNG_SEED: 12345
OUTPUT_PATH: './output/vl-bert/vrd'
MODULE: ResNetVLBERT
GPUS: '2'
LOG_FREQUENT: 100
VAL_FREQUENT: 1
CHECKPOINT_FREQUENT: 1
MODEL_PREFIX: 'vl-bert_base_res101_vrd'
NUM_WORKERS_PER_GPU: 4
SCALES:
- 600
- 1000

DATASET:
  DATASET: vrd
  LABEL_INDEX_IN_BATCH: 3
  APPEND_INDEX: false
  DATASET_PATH: './data/vrd'
  ROOT_PATH: './'
  TRAIN_IMAGE_SET: 'train'
  VAL_IMAGE_SET: 'test'
  TEST_IMAGE_SET: 'test'

  IMG_FLIPPED: true

  ALL_PROPOSALS_TEST: true
  MAX_NB_OF_OBJ: 20

NETWORK:
  PARTIAL_PRETRAIN: "./model/pretrained_model/vl-bert-base-e2e.model" # "./model/pretrained_model/vl-bert-base-prec.model"
  PARTIAL_PRETRAIN_PREFIX_CHANGES:
  - "vlbert.mlm_head.predictions.transform->final_mlp.0"
  - "module.vlbert.mlm_head.predictions.transform->module.final_mlp.0"
  - "vlbert->vlbert"
  - "module.vlbert->module.vlbert"
  IMAGE_NUM_LAYERS: 101
  IMAGE_C5_DILATED: true
  IMAGE_STRIDE_IN_1x1: true
  PIXEL_MEANS:
  - 102.9801
  - 115.9465
  - 122.7717
  PIXEL_STDS:
  - 1.0
  - 1.0
  - 1.0
  IMAGE_FEAT_PRECOMPUTED: false
  IMAGE_PRETRAINED: './model/pretrained_model/resnet101-pt-vgbua'
  IMAGE_PRETRAINED_EPOCH: 0
  IMAGE_FROZEN_BACKBONE_STAGES:
  - 1
  - 2
  IMAGE_FROZEN_BN: true
  IMAGE_FINAL_DIM: 768
  IMAGE_SEMANTIC: false
  OUTPUT_CONV5: false
  BERT_MODEL_NAME: './model/pretrained_model/bert-base-uncased'
  BERT_PRETRAINED: ''
  BERT_PRETRAINED_EPOCH: 0
  BERT_FROZEN: false
  ENABLE_CNN_REG_LOSS: false
  
  # whether use spatial model
  USE_SPATIAL_MODEL: true
  SPA_CONCAT: true

  VLBERT:
    input_transform_type: 1
    visual_size: 768
    hidden_size: 768
    num_hidden_layers: 12
    num_attention_heads: 12
    intermediate_size: 3072
    hidden_act: "gelu"
    hidden_dropout_prob: 0.1
    attention_probs_dropout_prob: 0.1
    max_position_embeddings: 512
    type_vocab_size: 3
    vocab_size: 30522
    initializer_range: 0.02
    visual_scale_text_init: 0.0
    visual_scale_object_init: 0.0
    visual_ln: true
    # Let image regions with increasing order for position embedding
    use_img_region_order: false

    # freeze all parameters of VL-BERT but the last layer
    vlbert_frozen: true
    vlbert_unfrozen_layers: 0

    # Use enhanced image feature for text embedding part
    ENHANCED_IMG_FEATURE: false
    mask_weight: -1 # <0 means no weighting (naive summation)
    NO_PREDICATE: true
    # below mask_loss_*: only choose ONE to be true!
    mask_loss_sum: false
    mask_loss_mse: false

  CLASSIFIER_TYPE: "mlm" # "mlm"
  CLASSIFIER_PRETRAINED: true # false
  CLASSIFIER_DROPOUT: 0.5

TRAIN:
  SHUFFLE: true
  FLIP_PROB: 0.5
  BATCH_IMAGES: 1
  GRAD_ACCUMULATE_STEPS: 1
  ASPECT_GROUPING: false
  RESUME: false
  AUTO_RESUME: false # true # train from scratch each time!
  BEGIN_EPOCH: 0
  END_EPOCH: 60
  OPTIMIZER: 'AdamW'
  CLIP_GRAD_NORM: 1.0
  LR: 1.0e-4
  LR_SCHEDULE: 'triangle'
  WD: 0.0001
  WARMUP: true
  WARMUP_METHOD: 'linear'
  WARMUP_FACTOR: 0.0
  WARMUP_STEPS: 500
  FP16: false
  FP16_LOSS_SCALE: 128.0
  # Use enhanced image feature for text embedding part -> add mask loss
  LOSS_LOGGERS:
  - "ans_loss,AnsLoss"
  # - "mask_loss,MaskLoss"
  # Sample relationship pairs with background:others = 1:3 
  # gt can be nb of 1~24 (max 34)
  # bg can be nb of 31~8
  SAMPLE_RELS: 32

VAL:
  SHUFFLE: false
  FLIP_PROB: 0
  BATCH_IMAGES: 1

TEST:
  NO_TEST: true
  SHUFFLE: false
  FLIP_PROB: 0
  TEST_EPOCH: 0
  BATCH_IMAGES: 1
